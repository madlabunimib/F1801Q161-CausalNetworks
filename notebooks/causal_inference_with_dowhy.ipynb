{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install dowhy==0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dowhy\n",
    "import dowhy.api\n",
    "import dowhy.datasets\n",
    "import dowhy.plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference with DoWhy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Alessio Zanga and Fabio Stella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook represents a quick-start guide to causal inference using the [DoWhy](https://github.com/microsoft/dowhy) package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DoWhy allows the generation of a dataset by specifying a set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df',\n",
       " 'treatment_name',\n",
       " 'outcome_name',\n",
       " 'common_causes_names',\n",
       " 'instrument_names',\n",
       " 'effect_modifier_names',\n",
       " 'frontdoor_variables_names',\n",
       " 'dot_graph',\n",
       " 'gml_graph',\n",
       " 'ate']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dowhy.datasets.linear_dataset(\n",
    "    beta = 1,\n",
    "    num_samples = int(1e4),\n",
    "    num_common_causes = 1,\n",
    "    num_frontdoor_variables = 1,\n",
    "    treatment_is_binary = True,\n",
    "    outcome_is_binary = True\n",
    ")\n",
    "list(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will return a dictionary with a Pandas DataFrame, along with a set of variables names and the true causal graph used for the sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, [treatment_name], outcome_name, _, _, _, _, _, causal_graph, ace = dataset.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After unpacking the values of the dictionary, it is possible to observe the assigned names to the data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('v0', 'y')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment_name, outcome_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also return the true average causal effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAAOCAYAAAB6pd+uAAAACXBIWXMAAA7EAAAOxAGVKw4bAAACp0lEQVRIDaWW/1EVMRDHD4cCGKgA6UCkAh8daAloBzr+9/5zoAO0BOhArEClA7ACkQ6en0+8vQm53OXAncnbzWb3m/2R5N3WZrPpgtbr9Wkv/4YfME7R3cZ6iy/xx+Y5OB96rJfwO+for3vdwNCdD5Ou20U+QXef6Trms3hbkSCGP3H8BL8UAL4DU3eM3EwSm6Y/NgZzDj+GJ0K2qO8Z7nOlEh57a3vW617AvzEO0aV44E28Z73zW/gODim5XmelnOdVdGlE+C31N5l3OQC+dtO9LjL9F+Rd1lJy6pHt8A9GHk8TLyWI0xvG6Iig+85YAW5F52ip/wqQmwqenbPAdkR6zaidGmPM42niRYIa3jFKik1cn6Ol/iZySyJ2rEYmGcWsxePbIHl3pSbedgb4z6X+6wWv0mP8sbXTNfJ+daynUwR3WttzzwUodXoJnh0MoKmqChhVVS7pv/wJ0uQMOF5W8b37KQknGWkrTcZT4pngEorKLbGt2cz5+7hcEtjwoDA/EQTdcDX6wKMJcXU0K+kB3jartbMeTtGdOPuhz/mT/QnaF9E7+eDoMr9n7LPm/7Bds0A+eI6pB6jDdoTnHRQMv2rb4yhMVuyp/vj51+JfwfCfaBBB4iKXfynxITKKZwrPDkq+RrUzHx10fY4e5U8wduEAPnQOOe0PHwWfbWw3r7CJo5qWmE/iRYKe26hOhtcdMrkuAXODXl7sD5ZBHsHzR0UYg/yswJqyf/b7yCkZuKdpxTCmgdDP4uWfajd4+U2YvmZ6wF/oXiHH8+0mfxgmXW60xN8ufWXUTsQKTL9/O7ifbh5PP8siQf0umKciIGvXxIsOam/AXuojuI+KfEgOWUDvq0fIT6aSmv44GKRBef9KSkVUyR5njD3Ej3CLKhlbWZgm3l/lsGReDkawDQAAAABJRU5ErkJggg==",
      "text/latex": [
       "$\\displaystyle 0.0292$"
      ],
      "text/plain": [
       "0.0292"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FD0</th>\n",
       "      <th>W0</th>\n",
       "      <th>v0</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.101090</td>\n",
       "      <td>-1.671592</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.272862</td>\n",
       "      <td>-1.377525</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.761740</td>\n",
       "      <td>-0.427812</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.469911</td>\n",
       "      <td>-2.095372</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002100</td>\n",
       "      <td>-1.576471</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.406907</td>\n",
       "      <td>-2.617531</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-0.140561</td>\n",
       "      <td>0.028068</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.227541</td>\n",
       "      <td>-2.028969</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-0.347695</td>\n",
       "      <td>-0.819795</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-0.130492</td>\n",
       "      <td>0.990937</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           FD0        W0     v0      y\n",
       "0    -0.101090 -1.671592  False   True\n",
       "1    -1.272862 -1.377525   True  False\n",
       "2    -0.761740 -0.427812  False  False\n",
       "3     0.469911 -2.095372  False   True\n",
       "4     0.002100 -1.576471  False  False\n",
       "...        ...       ...    ...    ...\n",
       "9995 -0.406907 -2.617531  False  False\n",
       "9996 -0.140561  0.028068  False  False\n",
       "9997  0.227541 -2.028969  False   True\n",
       "9998 -0.347695 -0.819795   True  False\n",
       "9999 -0.130492  0.990937  False   True\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step consists in constructing a causal model using the true graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dowhy.CausalModel(\n",
    "    data = data,\n",
    "    treatment = treatment_name,\n",
    "    outcome = outcome_name,\n",
    "    graph = causal_graph\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not a proper SCM as we seen in previous sessions. It is more like a container for the data and the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.view_model(layout=\"dot\")\n",
    "# from IPython.display import Image, display    # Run these lines if you are on local.\n",
    "# display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will enable the identification step by using a couple of handful methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the Estimand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimand identification tests for both backdoor and frontdoor criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimand type: nonparametric-ate\n",
      "\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "  d                     \n",
      "─────(Expectation(y|W0))\n",
      "d[v₀]                   \n",
      "Estimand assumption 1, Unconfoundedness: If U→{v0} and U→y then P(y|v0,W0,U) = P(y|v0,W0)\n",
      "\n",
      "### Estimand : 2\n",
      "Estimand name: iv\n",
      "No such variable found!\n",
      "\n",
      "### Estimand : 3\n",
      "Estimand name: frontdoor\n",
      "Estimand expression:\n",
      "Expectation(Derivative(y, [FD0])*Derivative([FD0], [v0]))\n",
      "Estimand assumption 1, Full-mediation: FD0 intercepts (blocks) all directed paths from v0 to y.\n",
      "Estimand assumption 2, First-stage-unconfoundedness: If U→{v0} and U→{FD0} then P(FD0|v0,U) = P(FD0|v0)\n",
      "Estimand assumption 3, Second-stage-unconfoundedness: If U→{FD0} and U→y then P(y|FD0, v0, U) = P(y|FD0, v0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the Average Causal Effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the estimand has been identified, we can proceed to the last estimation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    \"backdoor.linear_regression\",\n",
    "    \"backdoor.propensity_score_stratification\",\n",
    "    \"backdoor.propensity_score_weighting\",\n",
    "    \"backdoor.propensity_score_matching\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will iterate over the provided methods and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = {\n",
    "    method: model.estimate_effect(estimand, method_name=method)\n",
    "    for method in methods\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Causal Estimate ***\n",
      "\n",
      "## Identified estimand\n",
      "Estimand type: nonparametric-ate\n",
      "\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "  d                     \n",
      "─────(Expectation(y|W0))\n",
      "d[v₀]                   \n",
      "Estimand assumption 1, Unconfoundedness: If U→{v0} and U→y then P(y|v0,W0,U) = P(y|v0,W0)\n",
      "\n",
      "## Realized estimand\n",
      "b: y~v0+W0\n",
      "Target units: ate\n",
      "\n",
      "## Estimate\n",
      "Mean value: 0.019287447461825702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimate in estimates.values():\n",
    "    print(estimate)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Estimation Method: backdoor.linear_regression,\n",
      "    Estimated ACE: 0.01929,\n",
      "    Relative Error: 33.95%\n",
      "    \n",
      "    Estimation Method: backdoor.propensity_score_stratification,\n",
      "    Estimated ACE: 0.01722,\n",
      "    Relative Error: 41.04%\n",
      "    \n",
      "    Estimation Method: backdoor.propensity_score_weighting,\n",
      "    Estimated ACE: 0.01807,\n",
      "    Relative Error: 38.12%\n",
      "    \n",
      "    Estimation Method: backdoor.propensity_score_matching,\n",
      "    Estimated ACE: 0.0153,\n",
      "    Relative Error: 47.6%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for method, estimate in estimates.items():\n",
    "    print(f\"\"\"\n",
    "    Estimation Method: {method},\n",
    "    Estimated ACE: {estimate.value:.4},\n",
    "    Relative Error: {(abs((estimate.value-ace)/ace*100)):.4}%\n",
    "    \"\"\".lstrip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the estimates obtained we can setup a round of hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "refuters = [\n",
    "    \"bootstrap_refuter\",\n",
    "    \"data_subset_refuter\",\n",
    "    \"dummy_outcome_refuter\",\n",
    "    \"placebo_treatment_refuter\",\n",
    "    \"random_common_cause\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the backdoor with linear regression as estimate of reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "refuteds = {\n",
    "    refuter: model.refute_estimate(estimand, estimates[\"backdoor.linear_regression\"], method_name=refuter)\n",
    "    for refuter in refuters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some \"refuters\", as they are called in DoWhy, may return a list of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refute: Bootstrap Sample Dataset\n",
      "Estimated effect:0.019287447461825702\n",
      "New effect:0.01895048816849586\n",
      "p value:0.45999999999999996\n",
      "\n",
      "Refute: Use a subset of data\n",
      "Estimated effect:0.019287447461825702\n",
      "New effect:0.018970895924973037\n",
      "p value:0.45999999999999996\n",
      "\n",
      "Refute: Use a Dummy Outcome\n",
      "Estimated effect:0\n",
      "New effect:-0.0027021875754324664\n",
      "p value:0.45999999999999996\n",
      "\n",
      "Refute: Use a Placebo Treatment\n",
      "Estimated effect:0.019287447461825702\n",
      "New effect:-7.852935162945162e-05\n",
      "p value:0.5\n",
      "\n",
      "Refute: Add a Random Common Cause\n",
      "Estimated effect:0.019287447461825702\n",
      "New effect:0.019271989912366783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for refuter in refuteds.values():\n",
    "    print(refuter if type(refuter) != list else refuter[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your results may vary. Try to experiment with different graph configurations by altering the numbers of variables in the generation step.\n",
    "\n",
    "Have fun!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
